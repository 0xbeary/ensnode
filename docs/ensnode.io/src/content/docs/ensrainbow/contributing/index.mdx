---
title: ENSRainbow Development and Contributions
description: Learn how to run ENSRainbow locally for development and contributions.
sidebar:
  label: Overview
  order: 1
---

import { LinkCard } from "@astrojs/starlight/components";

:::note
This guide covers running ENSRainbow locally for development and contributions.
:::

## Local Development

:::caution[Follow ENSNode's Contribution Guide First]
Follow ENSNode's [contribution guide](/docs/contributing/) to prepare your workspace environment & install dependencies.
:::

### Get the Rainbow Table Data Files (`.ensrainbow`)

ENSRainbow ingests data from `.ensrainbow` files. These files contain labelhash-label pairs for a specific `LABEL_SET_ID` and `LABEL_SET_VERSION`. You can download these files using the `download-ensrainbow-files.sh` script located in `apps/ensrainbow/scripts/`.

The script requires two arguments: `LABEL_SET_ID` and `LABEL_SET_VERSION` (a non-negative integer).

```bash
# Navigate to the script directory (or call it from the monorepo root)
cd apps/ensrainbow

# Example: Download 'subgraph' label set ID, label set version 0 (original tables)
./scripts/download-ensrainbow-files.sh subgraph 0

# Example: Download 'searchlight' label set ID, label set version 0 (extended tables)
./scripts/download-ensrainbow-files.sh searchlight 0

# Example: Download 'discoveryA' label set ID, label set version 0 (initially empty for discovered labels)
./scripts/download-ensrainbow-files.sh discoveryA 0

# Example: Download 'ens-test-env' label set ID, label set version 0 (for test environment)
./scripts/download-ensrainbow-files.sh ens-test-env 0
```

This command will:

- Download the specified `<LABEL_SET_ID>-<LABEL_SET_VERSION>.ensrainbow` file.
- Download its corresponding checksum file (`<LABEL_SET_ID>-<LABEL_SET_VERSION>.ensrainbow.sha256sum`).
- Download its corresponding `<LABEL_SET_ID>-<LABEL_SET_VERSION>.ensrainbow.LICENSE.txt` file.
- Automatically verify the checksum of the `.ensrainbow` file.
- Place the files in `./labelsets/` (relative to where `OUT_DIR` is set, default is current dir).

Refer to the script for more details on output paths.

### Convert Legacy SQL Data (Optional)

If you have legacy rainbow tables in the `.sql.gz` format, you can convert them to the `.ensrainbow` format using the `convert` command:

```bash
# Example: Convert a legacy SQL file to subgraph-0.ensrainbow
pnpm run convert --input-file path/to/your/ens_names.sql.gz --output-file subgraph-0.ensrainbow
```
This will create `subgraph-0.ensrainbow` in the current directory.

### Ingest Rainbow Tables into LevelDB

Once you have your `.ensrainbow` files, you can ingest them into a LevelDB database using the `ingest-ensrainbow` command.

**Important Ingestion Rules:**

1.  **Initial Ingestion**: The first time you ingest data into a new or empty `--data-dir`, the input `.ensrainbow` file *must* be for `LABEL_SET_VERSION 0`. This initial ingestion will set the `LABEL_SET_ID` for the entire database.
2.  **Label Set ID Consistency**: All subsequent ingestions into the same `--data-dir` *must* use `.ensrainbow` files belonging to the *same* `LABEL_SET_ID` as the initial ingest.
3.  **Sequential Label Set Versions**: Each subsequent `.ensrainbow` file ingested *must* have a `LABEL_SET_VERSION` that is exactly one greater than the `HIGHEST_LABEL_SET_VERSION` currently stored in the database. For example, if the database contains data up to `subgraph-1.ensrainbow` (meaning `HIGHEST_LABEL_SET_VERSION` is 1), the next file to ingest must be `subgraph-2.ensrainbow`.

The database internally stores the `LABEL_SET_ID` and `HIGHEST_LABEL_SET_VERSION` to enforce these rules.

```bash
# Example: Initial ingest for 'subgraph' label set ID, label set version 0
pnpm run ingest-ensrainbow --input-file subgraph-0.ensrainbow --data-dir ./my-subgraph-data

# Example: Subsequent ingest for 'subgraph' label set ID, label set version 1
# (assuming subgraph-0.ensrainbow was already ingested into ./my-subgraph-data)
pnpm run ingest-ensrainbow --input-file subgraph-1.ensrainbow --data-dir ./my-subgraph-data
```

The `ingest-ensrainbow` command will verify the integrity of the data and update the database. If a new `.ensrainbow` file contains labelhashes already present, they are typically overridden with the new label set version. The command also recalculates and verifies the total unique label count after ingestion to ensure data integrity.

### Start ENSRainbow

After ingesting data:
```bash
pnpm run serve --data-dir ./my-subgraph-data
```

You can verify the service is running by checking the health endpoint or retrieving the label count:

```bash
# Health check
curl http://localhost:3223/health

# Get count of healable labels
curl http://localhost:3223/v1/labels/count

# Heal a labelhash (basic request)
curl http://localhost:3223/v1/heal/0xYourLabelHash

# Heal a labelhash specifying label_set_id and label_set_version
# (label_set_id must match DB, label_set_version <= HIGHEST_LABEL_SET_VERSION in DB)
curl http://localhost:3223/v1/heal/0xYourLabelHash?label_set_id=subgraph&label_set_version=1
```
If `label_set_id` and `label_set_version` are provided in a heal request, both must be present. The server will validate them against the database's stored label set ID and highest label set version.

Expected count as of January 30, 2024: 133,856,894 unique 
label-labelhash pairs

### Downloading Pre-built Database Archives

As an alternative to ingesting `.ensrainbow` files sequentially, you can download pre-built LevelDB database archives. These are `.tgz` archives containing a complete database directory. Use the `download-prebuilt-database.sh` script from `apps/ensrainbow/scripts/`.

The script downloads a tarball (`.tgz`) containing the database. The script requires `DB_SCHEMA_VERSION`, `LABEL_SET_ID`, and `LABEL_SET_VERSION` (highest label set version included in the archive).

```bash
# Navigate to the script directory (or call it from the monorepo root)
cd apps/ensrainbow

# Example: Download schema v2, 'subgraph' label set ID, up to label set version 1
./scripts/download-prebuilt-database.sh v2 subgraph 1
```
This will download and verify `databases/v2/subgraph-1.tgz` (relative to `OUT_DIR`). You can then extract this archive to your desired data directory (e.g., `./my-subgraph-data`) and use it with `pnpm run serve`.

## Building the Docker Image

For instructions on building the ENSRainbow Docker image, see the [Building Docker Images](/ensrainbow/contributing/building) guide. The Docker build process can leverage these pre-built database archives or ingest `.ensrainbow` files.

<LinkCard
  title="Building ENSRainbow Docker Images"
  description="Learn how to build the ENSRainbow Docker image with various data sources"
  href="/ensrainbow/contributing/building"
/>

## Service Management

### Graceful Shutdown

The service handles graceful shutdown on SIGTERM and SIGINT signals (e.g., when receiving Ctrl+C or Docker stop commands).

### Database Management

If you need to start fresh with the database:

1. Stop any running ENSRainbow processes.
2. Delete the LevelDB data directory (default: './data').
3. Run the `ingest-ensrainbow` command(s) again as described in [Ingest Rainbow Tables](#ingest-rainbow-tables), or download and extract a [pre-built database archive](#downloading-pre-built-database-archives).

## System Requirements

### Data Ingestion Requirements (`convert` and `ingest-ensrainbow` commands)

- **Storage**:
  - Space for downloaded `.ensrainbow` files (varies by file).
  - ~7 GB for the LevelDB database after ingestion of a typical full dataset.
  - Additional temporary space during build/ingestion.
- **Memory**: At least 4 GB RAM recommended.

### API Server Requirements (`serve` command)

- **Storage**: ~7-8 GB for a typical LevelDB database. Docker image size will vary based on included data.
- **Memory**: Minimum 1 GB RAM (4 GB recommended for optimal performance).
- **CPU**: Minimal requirements.

## Command Line Interface

ENSRainbow provides a CLI for managing the service. Add `--help` for details on any command.

### Convert Legacy Data (`convert`)
Converts legacy `.sql.gz` rainbow tables to the `.ensrainbow` format.
```bash
pnpm run convert --input-file <path/to/ens_names.sql.gz> --output-file <LABEL_SET_ID-LABEL_SET_VERSION.ensrainbow>
```
- `--input-file`: Path to the gzipped SQL dump file.
- `--output-file`: Desired path for the output `.ensrainbow` file.

### Data Ingestion (`ingest-ensrainbow`)
Ingests data from `.ensrainbow` files into the LevelDB database.
```bash
pnpm run ingest-ensrainbow --input-file <path/to/LABEL_SET_ID-LABEL_SET_VERSION.ensrainbow> [--data-dir path/to/db]
```
- `--input-file`: Path to the `.ensrainbow` file. Adheres to [ingestion rules](#ingest-rainbow-tables).
- `--data-dir`: Directory for the LevelDB database (default: `data/`). The database stores `LABEL_SET_ID` and `HIGHEST_LABEL_SET_VERSION` metadata.

### Database Validation (`validate`)
```bash
pnpm run validate [--data-dir path/to/db] [--lite]
```

Validates database integrity by:

- Verifying the keys for all rainbow records are valid labelhashes
- Ensuring stored labels match their corresponding labelhashes
- Validating the total rainbow record count
- Verifying no ingestion was interrupted before successful completion

The `--lite` option performs a faster, less thorough validation by skipping hash verification and record count validation. It only checks that:

- The ingestion was completed successfully
- The schema version is correct
- The precalculated count exists and can be retrieved

The process will exit with:

- Code 0: Validation successful
- Code 1: Validation failed or errors encountered

### Database Purge

### Database Purge (`purge`)
```bash
pnpm run purge [--data-dir path/to/db]
```

Completely removes all files from the specified data directory. This is useful when you need to start fresh with a clean database.

The process will exit with:

- Code 0: Successful purge
- Code 1: Error during purge operation


### API Server (`serve`)
```bash
pnpm run serve [--port 3223] [--data-dir path/to/db]
```

Starts the API server. The process will exit with:

- Code 0: Clean shutdown
- Code 1: Error during operation

## Using ENSRainbow with ens-test-env

The ens-test-env project provides a test environment for ENS development. It includes a small dataset of ENS names in the `ens_test_env_names.sql.gz` file that can be used with ENSRainbow for testing purposes.

### Ingesting ens_test_env_names.sql.gz

To ingest the test data into ENSRainbow:

1.  **Convert Test Data (if needed):**
    If you don't have a pre-converted `ens-test-env-0.ensrainbow` file:
    ```bash
    # Navigate to apps/ensrainbow or adjust paths accordingly
    pnpm run convert --input-file test/fixtures/ens_test_env_names.sql.gz --output-file ens-test-env-0.ensrainbow
    ```
    This creates `ens-test-env-0.ensrainbow`.

2.  **Download Test Data (Alternative):**
    Alternatively, download the pre-defined test data file:
    ```bash
    # In apps/ensrainbow directory
    ./scripts/download-ensrainbow-files.sh ens-test-env 0
    ```
    This will place `ens-test-env-0.ensrainbow` in `labelsets/`. Adjust the path for the ingest command accordingly.

### Ingesting Test Data

```bash
# Assuming ens-test-env-0.ensrainbow is in the current directory or accessible by path
pnpm run ingest-ensrainbow --input-file ens-test-env-0.ensrainbow --data-dir data_ens_test_env
```

### Validating the Test Data

```bash
pnpm validate --data-dir data_ens_test_env
```

### Running ENSRainbow with Test Data

```bash
pnpm serve --data-dir data_ens_test_env --port 3223
```

### Using with Docker

You can also run ENSRainbow with the test data using Docker. This involves running the standard ENSRainbow image and configuring it via environment variables to download and use the test dataset.

1.  **Ensure you have the standard ENSRainbow Docker image:**
    If you haven't already, pull the latest image:
    ```bash
    docker pull ghcr.io/namehash/ensnode/ensrainbow:latest
    ```

2.  **Run the ENSRainbow container with test data configuration:**
    You'll need to mount a volume for persistent storage and set the `DB_SCHEMA_VERSION`, `LABEL_SET_ID`, and `LABEL_SET_VERSION` environment variables to point to the test data.
    ```bash
    # Create a directory on your host machine for test data, e.g., ~/my_ensrainbow_test_data
    mkdir -p ~/my_ensrainbow_test_data

    docker run -d --name ensrainbow_test_env \
      -v ~/my_ensrainbow_test_data:/app/apps/ensrainbow/data \
      -e DB_SCHEMA_VERSION="3" \
      -e LABEL_SET_ID="ens-test-env" \
      -e LABEL_SET_VERSION="0" \
      -p 3223:3223 \
      ghcr.io/namehash/ensnode/ensrainbow:latest
    ```
    *   Adjust `DB_SCHEMA_VERSION`, `LABEL_SET_ID`, and `LABEL_SET_VERSION` if the test data parameters differ. Typically, for the standard test data, `LABEL_SET_ID` is `ens-test-env` and `LABEL_SET_VERSION` is `0`. The `DB_SCHEMA_VERSION` should match the version of the database archives you intend to use (e.g., `3`).

This setup allows the `entrypoint.sh` script within the container to download the `ens-test-env-0` database archive into the mounted volume on its first run. Subsequent runs will reuse the data from the volume.

This test environment setup is particularly useful for running ENS tests (i.e. ens-test-env) that require label healing capabilities without needing the full production dataset.

### Environment Variables

When using ENSRainbow with Docker, the following environment variables control which pre-built ENSRainbow database archive is downloaded and used:

- **`DB_SCHEMA_VERSION`**: Specifies the database schema version (e.g., `3`). This determines the format and structure of the pre-built ENSRainbow database archives and is not related to the API version.
  - **Goal**: Ensures compatibility between the ENSRainbow software and the structure of downloaded database files that are prebuilt for startup-time optimizations.
  - **Configuration**: It is strongly recommended to use the latest available schema version unless you have specific compatibility requirements.

- **`LABEL_SET_ID`**: The identifier for a **Label Set**, which is a collection of ENS labelhash-to-label mappings from a specific source.
  - **Goal**: To enable the extensible definition of new label sets (e.g., subgraph vs. production vs. test).
  - **Configuration**: Choose the label set ID that matches your needs: 
    - `subgraph` - Main production dataset from The Graph's ENS subgraph
    - `searchlight` - Extended dataset with additional label discoveries
    - `discoveryA` - Dataset for dynamically discovered labels (initially empty)
    - `ens-test-env` - Small test dataset for development and testing. It is perfectly aligned with the set of labels expected by the [ens-test-env](https://github.com/ensdomains/ens-test-env).

- **`LABEL_SET_VERSION`**: A non-negative integer representing the version of a **Label Set**.
  - **Goal**: To support the deterministic evolution of datasets over time, allowing services to achieve reproducible results.
  - **Configuration**: Use the highest available version number for the most up-to-date data. Versions are sequential and incremental:
    - `0` - The initial/base version of the **Label Set**.
    - `1`, `2`, etc. - Incremental updates to the **Label Set**.

**Example combinations:**
```bash
# Latest production data
DB_SCHEMA_VERSION=3 LABEL_SET_ID=subgraph LABEL_SET_VERSION=0

# Test environment data
DB_SCHEMA_VERSION=3 LABEL_SET_ID=ens-test-env LABEL_SET_VERSION=0

# Extended discovery data
DB_SCHEMA_VERSION=3 LABEL_SET_ID=searchlight LABEL_SET_VERSION=0
```

### Persistent Storage with Docker

The ENSRainbow Docker image (built with the combined Dockerfile) now includes an `entrypoint.sh` script that supports persistent storage for the LevelDB database. This prevents re-downloading the database every time the container starts.

**How it Works:**

1.  **On First Run (with an empty volume):**
    *   The script requires `DB_SCHEMA_VERSION`, `LABEL_SET_ID`, and `LABEL_SET_VERSION` environment variables to be set.
    *   It downloads the specified database archive into `/app/apps/ensrainbow/data` (the designated data directory).
    *   After successful download, extraction, and validation, it creates a marker file (`.ensrainbow_db_ready`) in the data directory.
2.  **On Subsequent Runs:**
    *   The script checks for the presence of the data directory and the marker file.
    *   If found and the data passes a quick validation, it skips the download and uses the existing database.
    *   If the data is missing, invalid, or the marker file isn't present, it will attempt to download it again (requiring the environment variables).

**Using Docker Volumes:**

To ensure the database persists even if the container is removed and recreated, you **must** mount a Docker volume to `/app/apps/ensrainbow/data` inside the container.

**Example with a Host Directory:**

```bash
# Create a directory on your host machine first, e.g., ~/my_ensrainbow_data
mkdir -p ~/my_ensrainbow_data

docker run -d --name ensrainbow_persistent \
  -v ~/my_ensrainbow_data:/app/apps/ensrainbow/data \
  -e DB_SCHEMA_VERSION="3" \
  -e LABEL_SET_ID="subgraph" \
  -e LABEL_SET_VERSION="0" \
  -p 3223:3223 \
  ghcr.io/namehash/ensnode/ensrainbow:latest
```

**Example with a Named Docker Volume (Recommended):**

```bash
# Create a named volume (only needs to be done once)
docker volume create ensrainbow_db_volume

docker run -d --name ensrainbow_persistent \
  -v ensrainbow_db_volume:/app/apps/ensrainbow/data \
  -e DB_SCHEMA_VERSION="3" \
  -e LABEL_SET_ID="subgraph" \
  -e LABEL_SET_VERSION="0" \
  -p 3223:3223 \
  ghcr.io/namehash/ensnode/ensrainbow:latest
```

Adjust `DB_SCHEMA_VERSION`, `LABEL_SET_ID`, and `LABEL_SET_VERSION` as needed for the initial download.

Using a volume ensures that your downloaded and ingested data is not lost when the container stops or is removed, saving time and bandwidth on subsequent runs.

## Generating and Uploading Database Archives

:::note
These steps are typically performed by project maintainers for releasing official pre-built ENSRainbow database archives. Assumes `rclone` is configured with a remote named `ENSRAINBOWR2`.
:::

### 1. Prepare `.ensrainbow` Files

This section covers the conversion of source data (like SQL dumps or empty files for initial datasets) into the `.ensrainbow` format. The `time` command is used here to measure the duration of potentially long-running conversion processes.

**For the `subgraph` Label Set (main dataset):**
This command converts a SQL dump file (`ens_names.sql.gz`) into an `.ensrainbow` file for version 0 of the `subgraph` Label Set.
```bash
# Assuming ens_names.sql.gz contains the primary dataset
time pnpm run convert --input-file ens_names.sql.gz --output-file subgraph_0.ensrainbow --label-set-id subgraph --label-set-version 0
```

**For the `discoveryA` Label Set (initially empty for discovered labels):**
This creates an empty `.ensrainbow` file for version 0 of the `discoveryA` Label Set, which is used for labels discovered dynamically.
```bash
touch empty.sql
gzip empty.sql
time pnpm run convert --input-file empty.sql.gz --output-file discoveryA_0.ensrainbow --label-set-id discoveryA --label-set-version 0
```

**For the `ens-test-env` Label Set (for testing):**
This converts a test dataset SQL dump into an `.ensrainbow` file for version 0 of the `ens-test-env` Label Set.
```bash
time pnpm run convert --input-file test/fixtures/ens_test_env_names.sql.gz --output-file ens-test-env_0.ensrainbow --label-set-id ens-test-env --label-set-version 0
```

### 2. Upload `.ensrainbow` Files to R2 Storage

After generation, these `.ensrainbow` files are uploaded to the designated cloud storage (e.g., R2 via rclone).
```bash
rclone copy ./subgraph_0.ensrainbow ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./discoveryA_0.ensrainbow ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./ens-test-env_0.ensrainbow ENSRAINBOWR2:ensrainbow/labelsets/
```

### 3. Calculate and Upload Checksums for `.ensrainbow` Files

SHA256 checksums are generated for each `.ensrainbow` file to ensure data integrity. These checksum files are then uploaded.
```bash
# Calculate checksums
sha256sum subgraph_0.ensrainbow > subgraph_0.ensrainbow.sha256sum
sha256sum discoveryA_0.ensrainbow > discoveryA_0.ensrainbow.sha256sum
sha256sum ens-test-env_0.ensrainbow > ens-test-env_0.ensrainbow.sha256sum

# Upload checksums
rclone copy ./subgraph_0.ensrainbow.sha256sum ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./discoveryA_0.ensrainbow.sha256sum ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./ens-test-env_0.ensrainbow.sha256sum ENSRAINBOWR2:ensrainbow/labelsets/
```

### 4. Ingest `.ensrainbow` Files into LevelDB Databases

The `.ensrainbow` files are ingested into local LevelDB instances to create the actual databases.
```bash
pnpm ingest-ensrainbow --input-file subgraph_0.ensrainbow --data-dir ./data-subgraph_0
pnpm ingest-ensrainbow --input-file discoveryA_0.ensrainbow --data-dir ./data-discoveryA_0
pnpm ingest-ensrainbow --input-file ens-test-env_0.ensrainbow --data-dir ./data-ens-test-env_0
```

### 5. Package LevelDB Databases

The LevelDB data directories, now populated, are packaged into compressed `tar.gz` archives.
```bash
tar -czvf subgraph_0.tgz ./data-subgraph_0
tar -czvf discoveryA_0.tgz ./data-discoveryA_0
tar -czvf ens-test-env_0.tgz ./data-ens-test-env_0
```

### 6. Upload Database Archives to R2 Storage

These database archives are uploaded to cloud storage, tagged with a schema version (e.g., `3` in this example).
```bash
rclone copy ./subgraph_0.tgz ENSRAINBOWR2:ensrainbow/databases/3/
rclone copy ./discoveryA_0.tgz ENSRAINBOWR2:ensrainbow/databases/3/
rclone copy ./ens-test-env_0.tgz ENSRAINBOWR2:ensrainbow/databases/3/
```

### 7. Calculate and Upload Checksums for Database Archives

Finally, checksums for the database archives are calculated and uploaded to ensure their integrity.
```bash
# Calculate checksums
sha256sum subgraph_0.tgz > subgraph_0.tgz.sha256sum
sha256sum discoveryA_0.tgz > discoveryA_0.tgz.sha256sum
sha256sum ens-test-env_0.tgz > ens-test-env_0.tgz.sha256sum

# Upload checksums
rclone copy ./subgraph_0.tgz.sha256sum ENSRAINBOWR2:ensrainbow/databases/3/
rclone copy ./discoveryA_0.tgz.sha256sum ENSRAINBOWR2:ensrainbow/databases/3/
rclone copy ./ens-test-env_0.tgz.sha256sum ENSRAINBOWR2:ensrainbow/databases/3/
```

