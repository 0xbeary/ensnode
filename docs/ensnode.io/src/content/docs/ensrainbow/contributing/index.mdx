---
title: ENSRainbow Development and Contributions
description: Learn how to run ENSRainbow locally for development and contributions.
sidebar:
  label: Overview
  order: 1
---

import { LinkCard } from "@astrojs/starlight/components";

:::note
This guide covers running ENSRainbow locally for development and contributions.
:::

## Local Development

:::caution[Follow ENSNode's Contribution Guide First]
Follow ENSNode's [contribution guide](/docs/contributing/) to prepare your workspace environment & install dependencies.
:::

### Get the Rainbow Table Data Files (`.ensrainbow`)

ENSRainbow ingests data from `.ensrainbow` files. These files contain labelhash-label pairs for a specific `NAMESPACE` and `LABEL_SET`. You can download these files using the `download-ensrainbow-files.sh` script located in `apps/ensrainbow/`.

The script requires two arguments: `NAMESPACE` and `LABEL_SET` (a non-negative integer).

```bash
# Navigate to the script directory (or call it from the monorepo root)
cd apps/ensrainbow

# Example: Download 'subgraph' namespace, label set 0 (original tables)
./download-ensrainbow-files.sh subgraph 0

# Example: Download 'searchlight' namespace, label set 0 (extended tables)
./download-ensrainbow-files.sh searchlight 0

# Example: Download 'discoveryA' namespace, label set 0 (initially empty for discovered labels)
./download-ensrainbow-files.sh discoveryA 0

# Example: Download 'testenv' namespace, label set 0 (for test environment)
./download-ensrainbow-files.sh testenv 0
```

This command will:

- Download the specified `<NAMESPACE>-<LABEL_SET>.ensrainbow` file.
- Download its corresponding checksum file (`.sha256sum`).
- Download the `THE_GRAPH_LICENSE.txt` file.
- Automatically verify the checksum of the `.ensrainbow` file.
- Place the files in `./labelsets/<NAMESPACE>-<LABEL_SET>.ensrainbow` and `./THE_GRAPH_LICENSE.txt` respectively (relative to where `OUT_DIR` is set, default is current dir).

Refer to the script for more details on output paths.

### Convert Legacy SQL Data (Optional)

If you have legacy rainbow tables in the `.sql.gz` format, you can convert them to the `.ensrainbow` format using the `convert` command:

```bash
# Example: Convert a legacy SQL file to subgraph-0.ensrainbow
pnpm run convert --input-file path/to/your/ens_names.sql.gz --output-file subgraph-0.ensrainbow
```
This will create `subgraph-0.ensrainbow` in the current directory.

### Ingest Rainbow Tables into LevelDB

Once you have your `.ensrainbow` files, you can ingest them into a LevelDB database using the `ingest-ensrainbow` command.

**Important Ingestion Rules:**

1.  **Initial Ingestion**: The first time you ingest data into a new or empty `--data-dir`, the input `.ensrainbow` file *must* be for `LABEL_SET 0`. This initial ingestion will set the `NAMESPACE` for the entire database.
2.  **Namespace Consistency**: All subsequent ingestions into the same `--data-dir` *must* use `.ensrainbow` files belonging to the *same* `NAMESPACE` as the initial ingest.
3.  **Sequential Label Sets**: Each subsequent `.ensrainbow` file ingested *must* have a `LABEL_SET` that is exactly one greater than the `HIGHEST_LABEL_SET` currently stored in the database. For example, if the database contains data up to `subgraph-1.ensrainbow` (meaning `HIGHEST_LABEL_SET` is 1), the next file to ingest must be `subgraph-2.ensrainbow`.

The database internally stores the `NAMESPACE` and `HIGHEST_LABEL_SET` to enforce these rules.

```bash
# Example: Initial ingest for 'subgraph' namespace, label set 0
pnpm run ingest-ensrainbow --input-file subgraph-0.ensrainbow --data-dir ./my-subgraph-data

# Example: Subsequent ingest for 'subgraph' namespace, label set 1
# (assuming subgraph-0.ensrainbow was already ingested into ./my-subgraph-data)
pnpm run ingest-ensrainbow --input-file subgraph-1.ensrainbow --data-dir ./my-subgraph-data
```

The `ingest-ensrainbow` command will verify the integrity of the data and update the database. If a new `.ensrainbow` file contains labelhashes already present, they are typically overridden with the new label set version. The command also recalculates and verifies the total unique label count after ingestion to ensure data integrity.

### Start ENSRainbow

After ingesting data:
```bash
pnpm run serve --data-dir ./my-subgraph-data
```

You can verify the service is running by checking the health endpoint or retrieving the label count:

```bash
# Health check
curl http://localhost:3223/health

# Get count of healable labels
curl http://localhost:3223/v1/labels/count

# Heal a labelhash (basic request)
curl http://localhost:3223/v1/heal/0xYourLabelHash

# Heal a labelhash specifying namespace and label_set
# (namespace must match DB, label_set <= HIGHEST_LABEL_SET in DB)
curl http://localhost:3223/v1/heal/0xYourLabelHash?namespace=subgraph&label_set=1
```
If `namespace` and `label_set` are provided in a heal request, both must be present. The server will validate them against the database's stored namespace and highest label set.

Expected count as of January 30, 2024: 133,856,894 unique 
label-labelhash pairs

### Downloading Pre-built Database Artifacts

As an alternative to ingesting `.ensrainbow` files sequentially, you can download pre-built LevelDB database artifacts. These are `.tgz` archives containing a complete data directory. Use the `download-database-artifact.sh` script from `apps/ensrainbow/`.

The script requires `SCHEMA_VERSION`, `NAMESPACE`, and `LABEL_SET` (highest label set included in the artifact).

```bash
# Navigate to the script directory (or call it from the monorepo root)
cd apps/ensrainbow

# Example: Download schema v2, 'subgraph' namespace, up to label set 1
./download-database-artifact.sh v2 subgraph 1
```
This will download and verify `databases/v2/subgraph-1.tgz` (relative to `OUT_DIR`). You can then extract this archive to your desired data directory (e.g., `./my-subgraph-data`) and use it with `pnpm run serve`.

## Building the Docker Image

For instructions on building the ENSRainbow Docker image, see the [Building Docker Images](/ensrainbow/contributing/building) guide. The Docker build process can leverage these pre-built database artifacts or ingest `.ensrainbow` files.

<LinkCard
  title="Building ENSRainbow Docker Images"
  description="Learn how to build the ENSRainbow Docker image with various data sources"
  href="/ensrainbow/contributing/building"
/>

## Service Management

### Graceful Shutdown

The service handles graceful shutdown on SIGTERM and SIGINT signals (e.g., when receiving Ctrl+C or Docker stop commands).

### Database Management

If you need to start fresh with the database:

1. Stop any running ENSRainbow processes.
2. Delete the LevelDB data directory (default: './data').
3. Run the `ingest-ensrainbow` command(s) again as described in [Ingest Rainbow Tables](#ingest-rainbow-tables), or download and extract a [pre-built database artifact](#downloading-pre-built-database-artifacts).

## System Requirements

### Data Ingestion Requirements (`convert` and `ingest-ensrainbow` commands)

- **Storage**:
  - Space for downloaded `.ensrainbow` files (varies by file).
  - ~7 GB for the LevelDB database after ingestion of a typical full dataset.
  - Additional temporary space during build/ingestion.
- **Memory**: At least 4 GB RAM recommended.

### API Server Requirements (`serve` command)

- **Storage**: ~7-8 GB for a typical LevelDB database. Docker image size will vary based on included data.
- **Memory**: Minimum 1 GB RAM (4 GB recommended for optimal performance).
- **CPU**: Minimal requirements.

## Command Line Interface

ENSRainbow provides a CLI for managing the service. Add `--help` for details on any command.

### Convert Legacy Data (`convert`)
Converts legacy `.sql.gz` rainbow tables to the `.ensrainbow` format.
```bash
pnpm run convert --input-file <path/to/ens_names.sql.gz> --output-file <NAMESPACE-LABEL_SET.ensrainbow>
```
- `--input-file`: Path to the gzipped SQL dump file.
- `--output-file`: Desired path for the output `.ensrainbow` file.

### Data Ingestion (`ingest-ensrainbow`)
Ingests data from `.ensrainbow` files into the LevelDB database.
```bash
pnpm run ingest-ensrainbow --input-file <path/to/NAMESPACE-LABEL_SET.ensrainbow> [--data-dir path/to/db]
```
- `--input-file`: Path to the `.ensrainbow` file. Adheres to [ingestion rules](#ingest-rainbow-tables).
- `--data-dir`: Directory for the LevelDB database (default: `data/`). The database stores `NAMESPACE` and `HIGHEST_LABEL_SET` metadata.

### Database Validation (`validate`)
```bash
pnpm run validate [--data-dir path/to/db] [--lite]
```

Validates database integrity by:

- Verifying the keys for all rainbow records are valid labelhashes
- Ensuring stored labels match their corresponding labelhashes
- Validating the total rainbow record count
- Verifying no ingestion was interrupted before successful completion

The `--lite` option performs a faster, less thorough validation by skipping hash verification and record count validation. It only checks that:

- The ingestion was completed successfully
- The schema version is correct
- The precalculated count exists and can be retrieved

The process will exit with:

- Code 0: Validation successful
- Code 1: Validation failed or errors encountered

### Database Purge

### Database Purge (`purge`)
```bash
pnpm run purge [--data-dir path/to/db]
```

Completely removes all files from the specified data directory. This is useful when you need to start fresh with a clean database.

The process will exit with:

- Code 0: Successful purge
- Code 1: Error during purge operation


### API Server (`serve`)
```bash
pnpm run serve [--port 3223] [--data-dir path/to/db]
```

Starts the API server. The process will exit with:

- Code 0: Clean shutdown
- Code 1: Error during operation

## Using ENSRainbow with ens-test-env

The ens-test-env project provides a test environment for ENS development. It includes a small dataset of ENS names in the `ens_test_env_names.sql.gz` file that can be used with ENSRainbow for testing purposes.

### Ingesting ens_test_env_names.sql.gz

To ingest the test data into ENSRainbow:

1.  **Convert Test Data (if needed):**
    If you don't have a pre-converted `testenv-0.ensrainbow` file:
    ```bash
    # Navigate to apps/ensrainbow or adjust paths accordingly
    pnpm run convert --input-file test/fixtures/ens_test_env_names.sql.gz --output-file testenv-0.ensrainbow
    ```
    This creates `testenv-0.ensrainbow`.

2.  **Download Test Data (Alternative):**
    Alternatively, download the pre-defined test data file:
    ```bash
    # In apps/ensrainbow directory
    ./download-ensrainbow-files.sh testenv 0
    ```
    This will place `testenv-0.ensrainbow` in `labelsets/`. Adjust the path for the ingest command accordingly.

### Ingesting Test Data

```bash
# Assuming testenv-0.ensrainbow is in the current directory or accessible by path
pnpm run ingest-ensrainbow --input-file testenv-0.ensrainbow --data-dir data_ens_test_env
```

### Validating the Test Data

```bash
pnpm validate --data-dir data_ens_test_env
```

### Running ENSRainbow with Test Data

```bash
pnpm serve --data-dir data_ens_test_env --port 3223
```

### Using with Docker

You can also run ENSRainbow with the test data using Docker. This involves running the standard ENSRainbow image and configuring it via environment variables to download and use the test dataset.

1.  **Ensure you have the standard ENSRainbow Docker image:**
    If you haven't already, pull the latest image:
    ```bash
    docker pull ghcr.io/namehash/ensnode/ensrainbow:latest
    ```

2.  **Run the ENSRainbow container with test data configuration:**
    You'll need to mount a volume for persistent storage and set the `SCHEMA_VERSION`, `NAMESPACE`, and `LABEL_SET` environment variables to point to the test data.
    ```bash
    # Create a directory on your host machine for test data, e.g., ~/my_ensrainbow_test_data
    mkdir -p ~/my_ensrainbow_test_data

    docker run -d --name ensrainbow_test_env \
      -v ~/my_ensrainbow_test_data:/app/apps/ensrainbow/data \
      -e SCHEMA_VERSION="v3" \
      -e NAMESPACE="testenv" \
      -e LABEL_SET="0" \
      -p 3223:3223 \
      ghcr.io/namehash/ensnode/ensrainbow:latest
    ```
    *   Adjust `SCHEMA_VERSION`, `NAMESPACE`, and `LABEL_SET` if the test data parameters differ. Typically, for the standard test data, `NAMESPACE` is `testenv` and `LABEL_SET` is `0`. The `SCHEMA_VERSION` should match the version of the database artifact you intend to use (e.g., `v2`, `v3`).

This setup allows the `entrypoint.sh` script within the container to download the `testenv-0` database artifact into the mounted volume on its first run. Subsequent runs will reuse the data from the volume.

This test environment setup is particularly useful for running ENS tests (i.e. ens-test-env) that require label healing capabilities without needing the full production dataset.

### Environment Variables

When using ENSRainbow with Docker, the following environment variables control which database artifact is downloaded and used:

- **`SCHEMA_VERSION`**: The database schema version (e.g., `v3`). This determines the format and structure of the database artifacts. Use the latest available version unless you have specific compatibility requirements.

- **`NAMESPACE`**: The data namespace identifier that categorizes the type of ENS data:
  - `subgraph` - Main production dataset from The Graph's ENS subgraph
  - `searchlight` - Extended dataset with additional label discoveries
  - `discoveryA` - Dataset for dynamically discovered labels (initially empty)
  - `testenv` - Small test dataset for development and testing

- **`LABEL_SET`**: A non-negative integer representing the incremental dataset version within a namespace. Label sets are sequential:
  - `0` - Initial/base dataset for the namespace
  - `1`, `2`, etc. - Incremental updates containing additional or updated labels

**Example combinations:**
```bash
# Latest production data
SCHEMA_VERSION=v3 NAMESPACE=subgraph LABEL_SET=0

# Test environment data
SCHEMA_VERSION=v3 NAMESPACE=testenv LABEL_SET=0

# Extended discovery data
SCHEMA_VERSION=v3 NAMESPACE=searchlight LABEL_SET=0
```

### Persistent Storage with Docker

The ENSRainbow Docker image (built with the combined Dockerfile) now includes an `entrypoint.sh` script that supports persistent storage for the LevelDB database. This prevents re-downloading the database every time the container starts.

**How it Works:**

1.  **On First Run (with an empty volume):**
    *   The script requires `SCHEMA_VERSION`, `NAMESPACE`, and `LABEL_SET` environment variables to be set.
    *   It downloads the specified database artifact into `/app/apps/ensrainbow/data` (the designated data directory).
    *   After successful download, extraction, and validation, it creates a marker file (`.ensrainbow_db_ready`) in the data directory.
2.  **On Subsequent Runs:**
    *   The script checks for the presence of the data directory and the marker file.
    *   If found and the data passes a quick validation, it skips the download and uses the existing database.
    *   If the data is missing, invalid, or the marker file isn't present, it will attempt to download it again (requiring the environment variables).

**Using Docker Volumes:**

To ensure the database persists even if the container is removed and recreated, you **must** mount a Docker volume to `/app/apps/ensrainbow/data` inside the container.

**Example with a Host Directory:**

```bash
# Create a directory on your host machine first, e.g., ~/my_ensrainbow_data
mkdir -p ~/my_ensrainbow_data

docker run -d --name ensrainbow_persistent \
  -v ~/my_ensrainbow_data:/app/apps/ensrainbow/data \
  -e SCHEMA_VERSION="v2" \
  -e NAMESPACE="subgraph" \
  -e LABEL_SET="1" \
  -p 3223:3223 \
  ghcr.io/namehash/ensnode/ensrainbow:latest
```

**Example with a Named Docker Volume (Recommended):**

```bash
# Create a named volume (only needs to be done once)
docker volume create ensrainbow_db_volume

docker run -d --name ensrainbow_persistent \
  -v ensrainbow_db_volume:/app/apps/ensrainbow/data \
  -e SCHEMA_VERSION="v2" \
  -e NAMESPACE="subgraph" \
  -e LABEL_SET="1" \
  -p 3223:3223 \
  ghcr.io/namehash/ensnode/ensrainbow:latest
```

Adjust `SCHEMA_VERSION`, `NAMESPACE`, and `LABEL_SET` as needed for the initial download.

Using a volume ensures that your downloaded and ingested data is not lost when the container stops or is removed, saving time and bandwidth on subsequent runs.

## Generating and Uploading Data Artifacts

:::note
These steps are typically performed by project maintainers for releasing official ENSRainbow data artifacts. Assumes `rclone` is configured with a remote named `ENSRAINBOWR2`.
:::

### 1. Prepare `.ensrainbow` Files

This section covers the conversion of source data (like SQL dumps or empty files for initial datasets) into the `.ensrainbow` format. The `time` command is used here to measure the duration of potentially long-running conversion processes.

**For `subgraph` namespace (main dataset):**
This command converts a SQL dump file (`ens_names.sql.gz`) into an `.ensrainbow` file for the `subgraph` namespace and label set 0.
```bash
# Assuming ens_names.sql.gz contains the primary dataset
time pnpm run convert --input-file ens_names.sql.gz --output-file subgraph_0.ensrainbow --namespace subgraph --label-set 0
```

**For `discoveryA` namespace (initially empty for discovered labels):**
This creates an empty `.ensrainbow` file for the `discoveryA` namespace, which might be used for labels discovered dynamically.
```bash
touch empty.sql
gzip empty.sql
time pnpm run convert --input-file empty.sql.gz --output-file discoveryA_0.ensrainbow --namespace discoveryA --label-set 0
```

**For `testenv` namespace (for testing):**
This converts a test dataset SQL dump into an `.ensrainbow` file for the `testenv` namespace.
```bash
time pnpm run convert --input-file test/fixtures/ens_test_env_names.sql.gz --output-file testenv_0.ensrainbow --namespace testenv --label-set 0
```

### 2. Upload `.ensrainbow` Files to R2 Storage

After generation, these `.ensrainbow` files are uploaded to the designated cloud storage (e.g., R2 via rclone).
```bash
rclone copy ./subgraph_0.ensrainbow ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./discoveryA_0.ensrainbow ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./testenv_0.ensrainbow ENSRAINBOWR2:ensrainbow/labelsets/
```

### 3. Calculate and Upload Checksums for `.ensrainbow` Files

SHA256 checksums are generated for each `.ensrainbow` file to ensure data integrity. These checksum files are then uploaded.
```bash
# Calculate checksums
sha256sum subgraph_0.ensrainbow > subgraph_0.ensrainbow.sha256sum
sha256sum discoveryA_0.ensrainbow > discoveryA_0.ensrainbow.sha256sum
sha256sum testenv_0.ensrainbow > testenv_0.ensrainbow.sha256sum

# Upload checksums
rclone copy ./subgraph_0.ensrainbow.sha256sum ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./discoveryA_0.ensrainbow.sha256sum ENSRAINBOWR2:ensrainbow/labelsets/
rclone copy ./testenv_0.ensrainbow.sha256sum ENSRAINBOWR2:ensrainbow/labelsets/
```

### 4. Ingest `.ensrainbow` Files into LevelDB Databases

The `.ensrainbow` files are ingested into local LevelDB instances to create the actual databases.
```bash
pnpm ingest-ensrainbow --input-file subgraph_0.ensrainbow --data-dir ./data-subgraph_0
pnpm ingest-ensrainbow --input-file discoveryA_0.ensrainbow --data-dir ./data-discoveryA_0
pnpm ingest-ensrainbow --input-file testenv_0.ensrainbow --data-dir ./data-testenv_0
```

### 5. Package LevelDB Databases

The LevelDB data directories, now populated, are packaged into compressed `tar.gz` archives.
```bash
tar -czvf subgraph_0.tgz ./data-subgraph_0
tar -czvf discoveryA_0.tgz ./data-discoveryA_0
tar -czvf testenv_0.tgz ./data-testenv_0
```

### 6. Upload Database Archives to R2 Storage

These database archives are uploaded to cloud storage, tagged with a schema version (e.g., `v3` in this example).
```bash
rclone copy ./subgraph_0.tgz ENSRAINBOWR2:ensrainbow/databases/v3/
rclone copy ./discoveryA_0.tgz ENSRAINBOWR2:ensrainbow/databases/v3/
rclone copy ./testenv_0.tgz ENSRAINBOWR2:ensrainbow/databases/v3/
```

### 7. Calculate and Upload Checksums for Database Archives

Finally, checksums for the database archives are calculated and uploaded to ensure their integrity.
```bash
# Calculate checksums
sha256sum subgraph_0.tgz > subgraph_0.tgz.sha256sum
sha256sum discoveryA_0.tgz > discoveryA_0.tgz.sha256sum
sha256sum testenv_0.tgz > testenv_0.tgz.sha256sum

# Upload checksums
rclone copy ./subgraph_0.tgz.sha256sum ENSRAINBOWR2:ensrainbow/databases/v3/
rclone copy ./discoveryA_0.tgz.sha256sum ENSRAINBOWR2:ensrainbow/databases/v3/
rclone copy ./testenv_0.tgz.sha256sum ENSRAINBOWR2:ensrainbow/databases/v3/
```

